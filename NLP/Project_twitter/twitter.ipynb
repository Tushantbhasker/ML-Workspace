{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training data from the PC.\n",
    "data = pd.read_csv(r\"C:\\Users\\tushant\\Desktop\\ML\\NLP\\Project_twitter\\train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline', 'airline_sentiment_gold',\n",
       "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
       "       'tweet_created', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.text\n",
    "y = data.airline_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10980,)\n",
      "(10980,)\n"
     ]
    }
   ],
   "source": [
    "# Making numpy array of x and y\n",
    "x = x.values\n",
    "y = y.values\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the y array label \n",
    "# 0 for neutral\n",
    "# 1 for positive\n",
    "# 2 for neutral\n",
    "y_train = []\n",
    "for value in y:\n",
    "    if value == \"positive\":\n",
    "        y_train.append(1)\n",
    "    elif value == \"neutral\":\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        y_train.append(2)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 2 2 2 2 1 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train[0:10])\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the training data\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "stop = stopwords.words(\"english\")\n",
    "punctuation = list(string.punctuation)\n",
    "stop += punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "def clean_words(words):\n",
    "    output_words = []\n",
    "    words = words.split(\" \") #Making the seperate words\n",
    "    for word in words:\n",
    "        if word.lower() not in stop:\n",
    "            output_words.append(word)\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clean = [clean_words(a) for a in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@SouthwestAir scheduled morning, 2 days fact, yes..not sure evening flight one Cancelled Flightled'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = [\" \".join(a) for a in x_clean]\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_string, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(max_features = 100,ngram_range=(1, 2))\n",
    "x_t = count_vec.fit_transform(x_train)\n",
    "x_t.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agent', 'airline', 'airport', 'americanair', 'amp', 'another', 'back', 'bag', 'bags', 'call', 'can', 'cancelled', 'cancelled flightled', 'change', 'check', 'co', 'could', 'customer', 'customer service', 'day', 'delay', 'delayed', 'dm', 'even', 'first', 'flight', 'flightled', 'flights', 'fly', 'flying', 'gate', 'get', 'getting', 'go', 'going', 'good', 'got', 'great', 'guys', 'help', 'hold', 'home', 'hour', 'hours', 'http', 'http co', 'it', 'jetblue', 'know', 'last', 'late', 'like', 'lost', 'love', 'luggage', 'make', 'me', 'minutes', 'much', 'need', 'never', 'new', 'now', 'one', 'people', 'phone', 'plane', 'please', 'really', 'seat', 'see', 'service', 'southwestair', 'still', 'take', 'thank', 'thank you', 'thanks', 'that', 'ticket', 'time', 'today', 'told', 'tomorrow', 'trying', 'united', 'us', 'usairways', 've', 'virginamerica', 'wait', 'waiting', 'want', 'way', 'we', 'weather', 'worst', 'would', 'yes', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chossing the best parameters\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# clf = SVC()\n",
    "# grid = {'C' : [1e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "#        'gamma' : [1e-3, 5e-4, 1e-4, 5e-3]}\n",
    "# abc = GridSearchCV(clf, grid)\n",
    "# abc.fit(x_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=50000.0, gamma=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_t = count_vec.transform(x_test)\n",
    "# y_pred = svc.predict(x_test_t)\n",
    "# y_pred\n",
    "# svc.score(x_test_t, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data\n",
    "testing = pd.read_csv(r\"C:\\Users\\tushant\\Desktop\\ML\\NLP\\Project_twitter\\test_twitter_x_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline', 'airline_sentiment_gold', 'name',\n",
       "       'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
       "       'tweet_created', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "testing_data = testing.text\n",
    "print(type(testing_data))\n",
    "testing_data = testing_data.values\n",
    "print(type(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@AmericanAir car gng DFW. Pulled 1hr ago icy roads. On-hold AA since 1hr. Can't reach arpt AA2450. Wat 2 do?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clean_test = [clean_words(a) for a in testing_data]\n",
    "x_string_test = [\" \".join(a) for a in x_clean_test]\n",
    "x_string_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = count_vec.transform(x_string_test)\n",
    "x_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(x_t, y_train)\n",
    "y_pred = svc.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = []\n",
    "for value in y_pred:\n",
    "    if value == 1:\n",
    "        y_s.append(\"positive\")\n",
    "    elif value == 0:\n",
    "        y_s.append(\"neutral\")\n",
    "    else:\n",
    "        y_s.append(\"negative\")\n",
    "y_s = np.array(y_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"test.csv\",y_s,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [\"Very Good Service\"]\n",
    "s_clean_test = [clean_words(a) for a in s]\n",
    "s_string_test = [\" \".join(a) for a in s_clean_test]\n",
    "s_test = count_vec.transform(s_string_test)\n",
    "\n",
    "s_pred = svc.predict(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
