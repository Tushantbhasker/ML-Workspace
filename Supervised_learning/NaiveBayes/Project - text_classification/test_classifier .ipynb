{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data set.\n",
    "data = sklearn.datasets.load_files(r\"C:\\Users\\tushant\\Downloads\\Compressed\\20_newsgroups.tar\\20_newsgroups\\20_newsgroups\")\n",
    "# data = sklearn.datasets.load_files(r\"C:\\Users\\tushant\\Downloads\\Compressed\\20_newsgroups.tar\\20_newsgroups\\20_newsgroups\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assing the data set to different variables.\n",
    "x = data.data\n",
    "file_names = data.filenames\n",
    "y = data.target\n",
    "desc = data.DESCR\n",
    "target_names = data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19997,)\n",
      "19997\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(len(x))\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stop words\n",
    "import string\n",
    "punctuation = list(string.punctuation)\n",
    "stop_words = [\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\n",
    "\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\n",
    "\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\n",
    "\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\n",
    "\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\n",
    "\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\n",
    "\"any\",\n",
    "\"both\",\n",
    "\"each\",\n",
    "\"few\",\n",
    "\"more\",\n",
    "\"most\",\n",
    "\"other\",\n",
    "\"some\",\n",
    "\"such\",\n",
    "\"no\",\n",
    "\"nor\",\n",
    "\"not\",\n",
    "\"only\",\n",
    "\"own\",\n",
    "\"same\",\n",
    "\"so\",\n",
    "\"than\",\n",
    "\"too\",\n",
    "\"very\",\n",
    "\"s\",\n",
    "\"t\",\n",
    "\"can\",\n",
    "\"will\",\n",
    "\"just\",\n",
    "\"don\",\"\\n\"\n",
    "\"should\",\n",
    "\"now\"]\n",
    "stop_words += punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19924\n",
      "19924\n"
     ]
    }
   ],
   "source": [
    "# Some of the data points give error while decoding into string from bytes object.\n",
    "# So we skip them (79 data points are skipped)\n",
    "x_string = []\n",
    "pas = []\n",
    "for i in range(len(x)):\n",
    "    try:\n",
    "        x_string.append([x[i].decode('utf-8')])\n",
    "    except:\n",
    "        pas.append(i)\n",
    "y_string = []\n",
    "for i in range(len(y)):\n",
    "    if i in pas:\n",
    "        continue\n",
    "    else:\n",
    "        y_string.append(y[i])\n",
    "print(len(x_string))\n",
    "print(len(y_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_string, y_string, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14943\n",
      "4981\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wods dictionary\n",
    "def word_dict(x):\n",
    "    result = {}\n",
    "    row = 0\n",
    "    for st in x:\n",
    "        # a is a string\n",
    "        result[row] = {}\n",
    "        i = 0\n",
    "        a = st[0]\n",
    "        a += \" \"\n",
    "        for j in range(len(a)):\n",
    "            if a[j] == \" \":\n",
    "                b = a[i:j]\n",
    "                if b in result[row] and b not in stop_words:\n",
    "                    result[row][b] += 1\n",
    "                elif b not in result[row] and b not in stop_words:\n",
    "                    result[row][b] = 1\n",
    "                i = j+1\n",
    "        row += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = word_dict(x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!zaphod.mps.ohio-state.edu!darwin.sura.net!dtix.dt.navy.mil!oasys!cervi\\nFrom: cervi@oasys.dt.navy.mil (Mark Cervi)\\nNewsgroups: rec.motorcycles\\nSubject: Re: ++BIKE SOLD OVER NET 600 MILES AWAY!++\\nMessage-ID: <34370@oasys.dt.navy.mil>\\nDate: 15 Apr 93 18:23:07 GMT\\nReferences: <1993Apr12.204046.4203@magnus.acs.ohio-state.edu> <6130331@hplsla.hp.com>\\nOrganization: NSWC, Carderock Division, Annapolis, MD, USA\\nLines: 15\\n\\nIn article <6130331@hplsla.hp.com> kens@hplsla.hp.com (Ken Snyder) writes:\\n>\\n>> Any other bikes sold long distances out there...I\\'d love to hear about\\n>it!\\n\\nI bought my Moto Guzzi from a Univ of Va grad student in Charlottesville\\nlast spring.\\n\\n\\t     Mark Cervi, cervi@oasys.dt.navy.mil, (w) 410-267-2147\\n\\t\\t DoD #0603  MGNOC #12998  \\'87 Moto Guzzi SP-II\\n      \"What kinda bikes that?\" A Moto Guzzi. \"What\\'s that?\" Its Italian.\\n-- \\n\\n\\tMark Cervi, CARDEROCKDIV, NSWC Code 852, Annapolis, MD  21402\\n\\t\\t   cervi@oasys.dt.navy.mil, (w) 410-267-2147\\n']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of all the words\n",
    "def all_word(word):\n",
    "    output = []\n",
    "    word = word[0]\n",
    "    word = word.split(\" \")\n",
    "    for w in word:\n",
    "        if w.lower() not in stop_words:\n",
    "            output.append(w)\n",
    "    return output;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_clean = [all_word(x) for x in x_train ]\n",
    "document_test = [all_word(x) for x in x_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for document in document_clean:\n",
    "    all_words += document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "freq = nltk.FreqDist(all_words)\n",
    "common = freq.most_common(5000)\n",
    "features = [x[0] for x in common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the 2-D array for our training data\n",
    "x_training = np.zeros((len(x_train),len(features)))\n",
    "row = 0\n",
    "for x in x_train:\n",
    "    x = x[0]\n",
    "    x = x.split(\" \") # Gives each word of the paragraph\n",
    "    for a in x:\n",
    "        if a in features:\n",
    "            col = features.index(a)\n",
    "            x_training[row][col] += 1\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 8.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [52.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [11.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [98.,  1.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_training[10:30][10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the 2-D array for our testing data\n",
    "x_testing = np.zeros((len(document_test),len(features)))\n",
    "row = 0\n",
    "for x in document_test:\n",
    "    x = x[0]\n",
    "    x = x.split(\" \") # Gives each word of the paragraph\n",
    "    for a in x:\n",
    "        if a in features:\n",
    "#             print(features.index(a))\n",
    "            col = features.index(a)\n",
    "            x_testing[row][col] += 1\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_testing[689].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clg = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clg.fit(x_training,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clg.predict(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 19,  4,  4,  4, 19,  4,  4,  8, 19,  4,  4, 19,  4, 19,  8,  4,\n",
       "       19,  8, 19,  4, 19, 19, 19,  4,  8,  4,  4,  4,  8,  4,  4,  4,  4,\n",
       "        8, 19, 19, 19,  8,  8,  8,  4, 19,  8, 19,  8, 19,  8,  4,  8, 19,\n",
       "        8, 19,  8,  8,  8,  8,  8,  4,  4,  8,  8,  4,  4,  4,  4, 19,  4,\n",
       "        8, 19,  8, 19,  4, 19,  8,  4,  8,  4,  4,  8,  8,  8, 19,  4, 19,\n",
       "        8,  8, 19, 19,  4,  4, 19, 19, 19,  8, 19, 19, 19, 19,  8])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0   0 120   0   0   0  67   0   0   0   0   0   0   0   0   0\n",
      "    0  72]\n",
      " [  0   0   0   0  80   0   1   0  81   0   0   0   0   0   0   0   0   0\n",
      "    0  68]\n",
      " [  0   2   0   0  79   0   0   0  82   0   0   0   0   0   0   0   0   0\n",
      "    0  93]\n",
      " [  0   2   0   0  88   0   0   0 116   0   0   0   0   0   0   0   0   0\n",
      "    0  45]\n",
      " [  0   2   0   0 125   0   0   0  98   0   0   0   0   0   0   0   0   0\n",
      "    0  30]\n",
      " [  0   0   0   0 100   0   0   0  77   0   0   0   0   0   0   0   0   0\n",
      "    0  72]\n",
      " [  0   2   0   0  68   0   0   0  71   0   0   0   0   0   0   0   0   0\n",
      "    0  85]\n",
      " [  0   2   0   0  86   0   0   0 107   0   0   0   0   0   0   0   0   0\n",
      "    0  46]\n",
      " [  0   4   0   0  89   0   0   0 155   0   0   0   0   0   0   0   0   0\n",
      "    0   6]\n",
      " [  0   1   0   0 106   0   0   0 138   0   0   0   0   0   0   0   0   0\n",
      "    0   3]\n",
      " [  0   1   0   0 134   0   0   0 126   0   0   0   0   0   0   0   0   0\n",
      "    0   3]\n",
      " [  0   1   0   0  66   0   0   0  72   0   0   0   0   0   0   0   0   0\n",
      "    0 108]\n",
      " [  0   4   0   0  86   0   0   0 125   0   0   0   0   0   0   0   0   0\n",
      "    0  52]\n",
      " [  0   2   0   0 110   0   0   0  66   0   0   0   0   0   0   0   0   0\n",
      "    0  65]\n",
      " [  0   2   0   0  64   0   0   0  79   0   0   0   0   0   0   0   0   0\n",
      "    0  93]\n",
      " [  0   0   0   0 176   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  86]\n",
      " [  0   2   0   0  80   0   2   0  88   0   0   0   0   0   0   0   0   0\n",
      "    0  88]\n",
      " [  0   0   0   0  51   0   1   0  62   0   0   0   0   0   0   0   0   0\n",
      "    0 143]\n",
      " [  0   0   0   0  28   0   0   0  26   0   0   0   0   0   0   0   0   0\n",
      "    0 192]\n",
      " [  0   0   0   0  40   0   1   0  38   0   0   0   0   0   0   0   0   0\n",
      "    0 148]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08592652077896004"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clg.score(x_testing,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
